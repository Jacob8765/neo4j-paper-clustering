{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bolt://localhost:7687', 'neo4j', '123456789')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"NEO4J_URI\"), os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTLINE:\n",
    "#1. Connect to the database\n",
    "#2. Get the data\n",
    "#2. Check for the existing centroids (this can happen if partial clustering has been done)\n",
    "#3. Initialize K-Means on all the data, setting the initial centroids to the existing centroids\n",
    "#4. Run K-Means until convergence\n",
    "#5. Save the centroids to the database\n",
    "#6. For nodes that didn't have a relationship to a cluster before, add them. \n",
    "#7. For each centroid, compute its \"title\" property by taking the embeddings of the n-closest nodes and averaging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neo4j.api.ServerInfo at 0x28bb16750>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(\"neo4j://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "driver.get_server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the papers to the database\n",
    "import json\n",
    "PAPERS_DATA_PATH = \"extract/papers_data.json\"\n",
    "\n",
    "with open(PAPERS_DATA_PATH, 'r') as json_file:\n",
    "        papers_data = json.load(json_file)\n",
    "        #remove the papers with no abstract\n",
    "        papers_data = [paper for paper in papers_data if len(paper['abstract']) > 0]\n",
    "\n",
    "CIPHR = \"\"\"\n",
    "WITH $data as data\n",
    "UNWIND data as paper\n",
    "MERGE (p:Paper {title: paper.title})\n",
    "SET p.abstract = paper.abstract\n",
    "SET p.url = paper.url\n",
    "SET p.embeddings = paper.abstract_embedding\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(CIPHR, data=papers_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a vector index on the embeddings property\n",
    "#in neo4j you can do this with \n",
    "# CALL db.index.vector.createNodeIndex('paper-embeddings', 'Paper', 'embeddings', 1536, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 19\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Assuming you have already created a Neo4j driver instance\n",
    "# driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "GET_PAPERS = \"\"\"\n",
    "MATCH (p:Paper)\n",
    "WHERE p.embeddings IS NOT NULL\n",
    "RETURN p.title as title, p.abstract as abstract, p.url as url, p.embeddings as embeddings\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    papers_result = session.run(GET_PAPERS)\n",
    "    papers = [dict(record) for record in papers_result]\n",
    "    print(f\"Number of papers: {len(papers)}\")\n",
    "\n",
    "GET_CENTROIDS = \"\"\"\n",
    "MATCH (c:Centroid)\n",
    "RETURN c.coordinates as coordinates, c.title as centroid_title\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    centroids_result = session.run(GET_CENTROIDS)\n",
    "    centroids = [dict(record) for record in centroids_result]\n",
    "\n",
    "# papers, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2, 2, 1, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 1, 2, 2, 2],\n",
       "       dtype=int32),\n",
       " array([[ 0.00957119,  0.00659721,  0.01460397, ...,  0.00216391,\n",
       "         -0.02703943, -0.01040091],\n",
       "        [ 0.00425553,  0.00378272,  0.01124918, ..., -0.0180465 ,\n",
       "         -0.01018701, -0.0188333 ],\n",
       "        [-0.00924649,  0.0132581 ,  0.00046706, ..., -0.01001863,\n",
       "         -0.01145077, -0.01652182]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "K=3\n",
    "\n",
    "#convert the embeddings to a numpy array\n",
    "embeddings = np.array([paper['embeddings'] for paper in papers])\n",
    "\n",
    "#convert the centroids to a numpy array\n",
    "centroid_embeddings = np.array([centroid['coordinates'] for centroid in centroids])\n",
    "\n",
    "# if there aren't enough centroids, initialize the rest randomly\n",
    "if len(centroids) < K:\n",
    "    # Initialize the missing centroids randomly\n",
    "    if centroid_embeddings.shape[0] == 0:\n",
    "        centroid_embeddings = \"kmeans++\"\n",
    "    else:\n",
    "        centroid_embeddings = np.vstack([centroid_embeddings, np.random.rand(K - len(centroids), 1536)])\n",
    "\n",
    "#initialize the k-means algorithm\n",
    "kmeans = KMeans(n_clusters=K, init=centroid_embeddings, n_init=1)\n",
    "\n",
    "#fit the algorithm to the data\n",
    "predictions = kmeans.fit_predict(embeddings)\n",
    "predictions, kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the centroids to the database\n",
    "ADD_CENTROIDS = \"\"\"\n",
    "UNWIND $centroids as centroid\n",
    "MERGE (c:Centroid {id: centroid.id})\n",
    "SET c.coordinates = centroid.coordinates\n",
    "\"\"\"\n",
    "\n",
    "centroids = [{'id': i, 'coordinates': centroid} for i, centroid in enumerate(kmeans.cluster_centers_)]\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(ADD_CENTROIDS, centroids=centroids)\n",
    "\n",
    "#add the cluster relationships to the database\n",
    "ADD_CLUSTER_RELATIONSHIPS = \"\"\"\n",
    "UNWIND $data as d\n",
    "MATCH (p:Paper {title: d.title})\n",
    "MATCH (c:Centroid {id: d.cluster})\n",
    "MERGE (p)-[:PART_OF_CLUSTER]->(c)\n",
    "\"\"\"\n",
    "\n",
    "data = [{'title': paper['title'], 'cluster': prediction} for paper, prediction in zip(papers, predictions)]\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(ADD_CLUSTER_RELATIONSHIPS, data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cluster_id': 0,\n",
       "  'nearest_nodes': [{'title': 'Microbially Induced Carbonate Precipitation Using Microorganisms Enriched from Calcareous Materials in Marine Environments and Their Metabolites',\n",
       "    'score': 0.989421010017395},\n",
       "   {'title': 'Characteristics of bio-CaCO 3 from microbial bio-mineralization with different bacteria species',\n",
       "    'score': 0.9894202947616577},\n",
       "   {'title': 'Biocement Fabrication and Design Application for a Sustainable Urban Area',\n",
       "    'score': 0.9602454900741577}]},\n",
       " {'cluster_id': 1,\n",
       "  'nearest_nodes': [{'title': 'Getting into the groove: Opportunities to enhance the ecological value of hard coastal infrastructure using Ô¨Åne-scale surface textures',\n",
       "    'score': 0.9751214981079102},\n",
       "   {'title': 'Learning from nature to enhance Blue engineering of marine infrastructure',\n",
       "    'score': 0.9691004753112793},\n",
       "   {'title': 'Availability of microhabitats explains a widespread pattern and informs theory on ecological engineering of boulder reefs',\n",
       "    'score': 0.9644978046417236}]},\n",
       " {'cluster_id': 2,\n",
       "  'nearest_nodes': [{'title': 'Engineered Living Materials: Prospects and Challenges for Using Biological Systems to Direct the Assembly of Smart Materials',\n",
       "    'score': 0.9669255018234253},\n",
       "   {'title': 'Biocement Fabrication and Design Application for a Sustainable Urban Area',\n",
       "    'score': 0.9639508128166199},\n",
       "   {'title': 'Intelligent and smart biomaterials for sustainable 3D printing applications',\n",
       "    'score': 0.9600445628166199}]}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the title of each centroid\n",
    "AVERAGE_EMBEDDINGS = \"\"\"\n",
    "match(c:Centroid)\n",
    "call db.index.vector.queryNodes('paper-embeddings', 3, c.coordinates) YIELD node, score\n",
    "RETURN c.id as cluster_id, COLLECT({title: node.title, score: score}) AS nearest_nodes\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(AVERAGE_EMBEDDINGS, centroids=centroids)\n",
    "    centroids_with_nearest_nodes = [dict(record) for record in result]\n",
    "\n",
    "centroids_with_nearest_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [{'cluster_id': 0,\n",
       "   'title': 'Microbially Induced Carbonate Precipitation'},\n",
       "  {'cluster_id': 1,\n",
       "   'title': 'Ecological Enhancement of Coastal Infrastructure'},\n",
       "  {'cluster_id': 2, 'title': 'Engineered Living Materials'}]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "#langchain configuration\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"labels\", description=\"An array of objects of schema {cluster_id: int, title: str} representing the labels of each cluster. Only give one title per cluster. You are given data of a handful of papers, as well as the cluster they belong to. The score is a number betweeo 0-1 giving the confidence of the model that the paper belongs to the cluster. Make your labels general, remember you are only given a subset of the papers, there are many more and the label should represent all of them\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "    \"We are clustering research papers based on their embeddings. You are given the titles of some research papers, as well as their distance to the cluster. Give each cluster a unique name that is representative of the data it is close to. .\\n{format_instructions}\\n{clusters}\")]\n",
    "    ,\n",
    "    input_variables=[\"clusters\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "_input = prompt.format_prompt(clusters=centroids_with_nearest_nodes)\n",
    "output = chat_model(_input.to_messages())\n",
    "labels = output_parser.parse(output.content)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the labels, update the database\n",
    "UPDATE_CENTROID_TITLES = \"\"\"\n",
    "UNWIND $labels as label\n",
    "MATCH (c:Centroid {id: label.cluster_id})\n",
    "SET c.title = label.title\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(UPDATE_CENTROID_TITLES, labels=labels.get('labels'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
